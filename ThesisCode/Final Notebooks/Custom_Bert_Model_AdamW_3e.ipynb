{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Custom_Bert_Model_AdamW_3e.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d309cb3e578541de8a95791563efa0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58f1a7c7172343649f4693de98d291aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_837340b3b2b34e7085ab27dddaf53157",
              "IPY_MODEL_d757344ed8cd45ae956a9f8af9960c8e"
            ]
          }
        },
        "58f1a7c7172343649f4693de98d291aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "837340b3b2b34e7085ab27dddaf53157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df3bd1b491c742ff80153faa4c37752d",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 10853,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 128,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50f0c78bda614eb28167241a6809d39c"
          }
        },
        "d757344ed8cd45ae956a9f8af9960c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2290637fcd7d47f9ab78081d85d0b483",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 128/10853 [01:47&lt;2:28:02,  1.21it/s, loss=4.09]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5706923f2cb6441786ee67d138c42f59"
          }
        },
        "df3bd1b491c742ff80153faa4c37752d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50f0c78bda614eb28167241a6809d39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2290637fcd7d47f9ab78081d85d0b483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5706923f2cb6441786ee67d138c42f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "706TPsx8h6W4"
      },
      "source": [
        "Question answering comes in many forms. In this example, weâ€™ll look at the particular type of extractive QA that involves answering a question about a passage by highlighting the segment of the passage that answers the question. This involves fine-tuning a model which predicts a start position and an end position in the passage. We will use the Stanford Question Answering Dataset (SQuAD) 2.0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj1mSH1Ih6W8"
      },
      "source": [
        "## Prerequisites: \n",
        "\n",
        "1. Download and install the required libraries below.\n",
        "2. Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kppY3LDeDksP",
        "outputId": "04e8f017-0045-4231-8cdb-9fe60a17c577"
      },
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install wandb\n",
        "!pip install allennlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.26.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.26.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.26.6)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.18)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: transformers<4.9,>=4.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.8.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: boto3<2.0,>=1.14 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.18.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.8 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.0.12)\n",
            "Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: google-cloud-storage<1.42.0,>=1.38.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.41.1)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.1.96)\n",
            "Requirement already satisfied: checklist==0.0.11 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.0.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.26.0)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: wandb<0.12.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.19.5)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: torchvision<0.11.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch<1.10.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.9.0+cu102)\n",
            "Requirement already satisfied: iso-639 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (0.4.5)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (7.6.3)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (1.0.0)\n",
            "Requirement already satisfied: munch>=2.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (2.5.0)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (0.3.4)\n",
            "Requirement already satisfied: patternfork-nosql in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (3.6)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.14 in /usr/local/lib/python3.7/dist-packages (from boto3<2.0,>=1.14->allennlp) (1.21.14)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.14->boto3<2.0,>=1.14->allennlp) (1.26.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.14->boto3<2.0,>=1.14->allennlp) (2.8.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.32.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.3.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (57.2.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.26.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (21.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (3.17.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (2.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.8->allennlp) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.8->allennlp) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.0.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.3.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.8.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (2.4.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.24.0->google-cloud-storage<1.42.0,>=1.38.0->allennlp) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.8->allennlp) (3.5.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.11.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<4.9,>=4.1->allennlp) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.9,>=4.1->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.9,>=4.1->allennlp) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.9,>=4.1->allennlp) (0.10.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (3.5.4)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (5.0.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (2.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (1.3.1)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (1.0.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (3.1.18)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (0.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.12.0,>=0.10.0->allennlp) (7.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb<0.12.0,>=0.10.0->allennlp) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.12.0,>=0.10.0->allennlp) (4.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (1.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.10.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (0.8.11)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (0.16.0)\n",
            "Requirement already satisfied: backports.csv in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (1.0.7)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (18.6.1)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (6.0.8)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.6.3)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (20201018)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (8.5.2)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.7/dist-packages (from cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (3.3.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.7/dist-packages (from cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (2.0)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (2.7.1)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (3.3.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.7/dist-packages (from portend>=2.1.1->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (4.1.1)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser->patternfork-nosql->checklist==0.0.11->allennlp) (1.0.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (3.2.1)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp) (3.5.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (3.4.7)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (2.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (3.0.4)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (21.2.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist==0.0.11->allennlp) (1.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.9,>=4.1->allennlp) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB9bvbDfE1od"
      },
      "source": [
        "import torch\n",
        "import transformers as tfs\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import BertTokenizerFast,BertPreTrainedModel, BertConfig, BertModel, BertGenerationEncoder\n",
        "from transformers import AdamW, DistilBertTokenizerFast, DistilBertConfig\n",
        "from transformers.modeling_outputs import (\n",
        "    BaseModelOutput,\n",
        "    BaseModelOutputWithPastAndCrossAttentions,\n",
        "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
        "    CausalLMOutputWithCrossAttentions,\n",
        "    MaskedLMOutput,\n",
        "    MultipleChoiceModelOutput,\n",
        "    NextSentencePredictorOutput,\n",
        "    QuestionAnsweringModelOutput,\n",
        "    SequenceClassifierOutput,\n",
        "    TokenClassifierOutput,\n",
        ")\n",
        "import string, re\n",
        "import torch.nn as nn\n",
        "from allennlp.nn.util import masked_log_softmax, masked_max\n",
        "\n",
        "import math\n",
        "\n",
        "from transformers.activations import gelu\n",
        "from transformers.deepspeed import is_deepspeed_zero3_enabled\n",
        "from transformers.file_utils import (\n",
        "    add_code_sample_docstrings,\n",
        "    add_start_docstrings,\n",
        "    add_start_docstrings_to_model_forward,\n",
        "    replace_return_docstrings,\n",
        ")\n",
        "\n",
        "from transformers.modeling_utils import (\n",
        "    PreTrainedModel,\n",
        "    apply_chunking_to_forward,\n",
        "    find_pruneable_heads_and_indices,\n",
        "    prune_linear_layer,\n",
        ")\n",
        "from transformers.utils import logging\n",
        "import torch.nn.functional as F\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNBk0xHCLs2i",
        "outputId": "1378db8e-555f-4123-d242-f261b5730f22"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVF6jV8HLs2i"
      },
      "source": [
        "# Utility functions for Metrics evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TwI72oBEJio"
      },
      "source": [
        "# Removing articles and punctuation, and standardizing whitespace are all typical text processing steps\n",
        "\n",
        "\n",
        "def normalize_text(s):\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpD2Ko5fh6W9"
      },
      "source": [
        "# 1. Data Understanding\n",
        "\n",
        "In this section we will import the data & convert it correctly into paralell lists of contexts, questions and answers provided in the SQuAD 2.0 Dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg1PetBOh6W-"
      },
      "source": [
        "## **Download SQuAD 2.0 Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9exsRArh6XF"
      },
      "source": [
        "# Function to compute the exact match for an answer.\n",
        "# This will help us determine how accurately do our answers match with the suggested answers\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gagGxJUuh6XF"
      },
      "source": [
        "# Function to compute the F1 Statistic \n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4bMzsBLERpu"
      },
      "source": [
        "# Function to calculate exact match and exact F1 score for a particular training epoch\n",
        "def calculate_stats(input_ids,start,end,idx):\n",
        "    batch_start = 8*idx\n",
        "    batch_end = batch_start+8\n",
        "    data = val_qac[batch_start:batch_end]\n",
        "    em = 0\n",
        "    ef1 = 0\n",
        "    for i,d in enumerate(data):\n",
        "        answer_start = start[i]\n",
        "        answer_end = end[i]\n",
        "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[i][answer_start:answer_end]))\n",
        "        gold_ans = d['answers']\n",
        "        if len(gold_ans)==0:\n",
        "            gold_ans.append(\"\")\n",
        "        em_s= max((compute_exact_match(answer, g_answer)) for g_answer in gold_ans)\n",
        "        ef1_s = max((compute_f1(answer, g_answer)) for g_answer in gold_ans)\n",
        "        em+=em_s\n",
        "        ef1+=ef1_s\n",
        "    return em,ef1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnfgXnH-h6W-"
      },
      "source": [
        "Note : This dataset can be explored in the Hugging Face model hub (SQuAD V2), and can be alternatively downloaded with the ðŸ¤— NLP library with load_dataset(\"squad_v2\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgIZHZyUDmZc",
        "outputId": "5bbfea94-b44b-4e86-a90c-03c218c349c2"
      },
      "source": [
        "# ## Create a squad directory and download the train and evaluation datasets directly into the library\n",
        "!mkdir squad\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜squadâ€™: File exists\n",
            "--2021-08-05 13:55:52--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: â€˜squad/train-v2.0.jsonâ€™\n",
            "\n",
            "squad/train-v2.0.js 100%[===================>]  40.17M   120MB/s    in 0.3s    \n",
            "\n",
            "2021-08-05 13:55:54 (120 MB/s) - â€˜squad/train-v2.0.jsonâ€™ saved [42123633/42123633]\n",
            "\n",
            "--2021-08-05 13:55:55--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: â€˜squad/dev-v2.0.jsonâ€™\n",
            "\n",
            "squad/dev-v2.0.json 100%[===================>]   4.17M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-08-05 13:55:55 (127 MB/s) - â€˜squad/dev-v2.0.jsonâ€™ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBs3jApXh6W-"
      },
      "source": [
        "Below we will import the data and convert it into parallel lists of contexts, questions, and answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQI9qONYDyaV"
      },
      "source": [
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    combined_qac=[] #combined contexts, questions & answers\n",
        "    counter=0\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']  \n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                q_answers = qa['answers'].copy()\n",
        "                q_answers = list(map(lambda x:x['text'], q_answers))\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "                    combined_qac.append({'context':context,'question':question,'answers':q_answers})\n",
        "    return contexts, questions, answers, combined_qac\n",
        "\n",
        "train_contexts, train_questions, train_answers,train_qac = read_squad('squad/train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers, val_qac = read_squad('squad/dev-v2.0.json')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkXAOFYYD1El"
      },
      "source": [
        "Now that we have converted the data into parallel lists, let us assess what the dataset holds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElGLokGnh6W_",
        "outputId": "63fede1f-7df4-49e8-dcee-ba9099376198"
      },
      "source": [
        "len(train_contexts)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86821"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "TXSjnT9th6W_",
        "outputId": "5e31bd73-772f-4edb-e480-4aee6b1cb36c"
      },
      "source": [
        "train_contexts[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'BeyoncÃ© Giselle Knowles-Carter (/biËËˆjÉ’nseÉª/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of BeyoncÃ©\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xaCYtL8Yh6XA",
        "outputId": "f6a28672-4789-4b7f-fdba-a52018014494"
      },
      "source": [
        "train_questions[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'When did Beyonce start becoming popular?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JPA9Gfjh6XA",
        "outputId": "cb7eb432-e312-4885-e173-2ac4261f950a"
      },
      "source": [
        "train_answers[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': 269, 'text': 'in the late 1990s'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8qPk9Agh6XA",
        "outputId": "39c572b1-7608-4f17-856b-955547aceda2"
      },
      "source": [
        "len(train_qac)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86821"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWMPdyAdh6XA",
        "outputId": "b884ffc7-1712-4f71-af5d-aa4a5480fb0a"
      },
      "source": [
        "train_qac[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': ['in the late 1990s'],\n",
              " 'context': 'BeyoncÃ© Giselle Knowles-Carter (/biËËˆjÉ’nseÉª/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of BeyoncÃ©\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
              " 'question': 'When did Beyonce start becoming popular?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px5a1hmQh6XA"
      },
      "source": [
        "Inspecting Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivgw51-1h6XA",
        "outputId": "848319cd-160a-4dfc-ee6a-a6db4c3607ce"
      },
      "source": [
        "len(val_contexts)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "Pl68rraDh6XB",
        "outputId": "bec6ac87-abd4-4024-d462-6c3cf2ac848f"
      },
      "source": [
        "val_contexts[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vc8kYrZHh6XB",
        "outputId": "42e11af7-e049-4861-c67f-d1bd5bc21318"
      },
      "source": [
        "val_questions[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In what country is Normandy located?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_-aBLq5h6XB",
        "scrolled": true,
        "outputId": "d1c5cbc6-fb66-411b-84d0-2606285bf7d4"
      },
      "source": [
        "val_answers[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': 159, 'text': 'France'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2xEtz3Oh6XB",
        "outputId": "299507c2-5a34-4ed6-a984-b5afcc1d8d7d"
      },
      "source": [
        "val_qac[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': ['France', 'France', 'France', 'France'],\n",
              " 'context': 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.',\n",
              " 'question': 'In what country is Normandy located?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBLdzfcLh6XB"
      },
      "source": [
        "## Observations:\n",
        "\n",
        " - We have successfully created 3 subsets of both the training and validation sets\n",
        " - We gathered the following stats:\n",
        "     - **Training Data**\n",
        "         - Length: 86821\n",
        "         - The combined_qac shows the way things will work, i.e.: We submit a context & a question to the model & receive the answer already highlighted\n",
        "         - train_answers shows the answer for a particular question and the start index value\n",
        "     - **Validation Data**\n",
        "         - Length: 20302\n",
        "         - Similar to the train_qac we have created a val_qac to understand the validation dataset better as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIe33tfoh6XB"
      },
      "source": [
        "# 2. Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQTw3dNCh6XC"
      },
      "source": [
        "In this section we will prepare the data appropriately for modelling and training. \n",
        "\n",
        "We will extract token positions where answers begins & ends for train & validation data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxFfS5aIh6XC"
      },
      "source": [
        "The contexts and questions are just strings. The answers are dicts containing the subsequence of the passage with the correct answer as well as an integer indicating the character at which the answer begins. In order to train a model on this data we need (1) the tokenized context/question pairs, and (2) integers indicating at which token positions the answer begins and ends.\n",
        "\n",
        "First, letâ€™s get the character position at which the answer ends in the passage (we are given the starting position). Sometimes SQuAD answers are off by one or two characters, so we will also adjust for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_BJdJ1D8MW"
      },
      "source": [
        "## Index the answers and contexts in the training and validation sets. This will help us generate the tokens \n",
        "## and helpp get better answers for our questions\n",
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # sometimes squad answers are off by a character or two â€“ fix this\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og3yr3KbLs2r"
      },
      "source": [
        "# Creating Custom BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyohUX4FLs2t"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder class for Pointer-Net\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 n_layers,\n",
        "                 dropout,\n",
        "                 bidir):\n",
        "        \"\"\"\n",
        "        Initiate Encoder\n",
        "\n",
        "        :param Tensor embedding_dim: Number of embbeding channels\n",
        "        :param int hidden_dim: Number of hidden units for the LSTM\n",
        "        :param int n_layers: Number of layers for LSTMs\n",
        "        :param float dropout: Float between 0-1\n",
        "        :param bool bidir: Bidirectional\n",
        "        \"\"\"\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim//2 if bidir else hidden_dim\n",
        "        self.n_layers = n_layers*2 if bidir else n_layers\n",
        "        self.bidir = bidir\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            self.hidden_dim,\n",
        "                            n_layers,\n",
        "                            dropout=dropout,\n",
        "                            bidirectional=bidir)\n",
        "\n",
        "        # Used for propagating .cuda() command\n",
        "        self.h0 = Parameter(torch.zeros(1), requires_grad=False)\n",
        "        self.c0 = Parameter(torch.zeros(1), requires_grad=False)\n",
        "\n",
        "    def forward(self, embedded_inputs,\n",
        "                hidden):\n",
        "        \"\"\"\n",
        "        Encoder - Forward-pass\n",
        "\n",
        "        :param Tensor embedded_inputs: Embedded inputs of Pointer-Net\n",
        "        :param Tensor hidden: Initiated hidden units for the LSTMs (h, c)\n",
        "        :return: LSTMs outputs and hidden units (h, c)\n",
        "        \"\"\"\n",
        "\n",
        "        embedded_inputs = embedded_inputs.permute(1, 0, 2)\n",
        "\n",
        "        outputs, hidden = self.lstm(embedded_inputs, hidden)\n",
        "\n",
        "        return outputs.permute(1, 0, 2), hidden\n",
        "\n",
        "    def init_hidden(self, embedded_inputs):\n",
        "        \"\"\"\n",
        "        Initiate hidden units\n",
        "\n",
        "        :param Tensor embedded_inputs: The embedded input of Pointer-NEt\n",
        "        :return: Initiated hidden units for the LSTMs (h, c)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = embedded_inputs.size(0)\n",
        "\n",
        "        # Reshaping (Expanding)\n",
        "        h0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.n_layers,\n",
        "                                                      batch_size,\n",
        "                                                      self.hidden_dim)\n",
        "        c0 = self.h0.unsqueeze(0).unsqueeze(0).repeat(self.n_layers,\n",
        "                                                      batch_size,\n",
        "                                                      self.hidden_dim)\n",
        "\n",
        "        return h0, c0\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention model for Pointer-Net\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim,\n",
        "                 hidden_dim):\n",
        "        \"\"\"\n",
        "        Initiate Attention\n",
        "\n",
        "        :param int input_dim: Input's diamention\n",
        "        :param int hidden_dim: Number of hidden units in the attention\n",
        "        \"\"\"\n",
        "\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.input_linear = nn.Linear(input_dim, hidden_dim)\n",
        "        self.context_linear = nn.Conv1d(input_dim, hidden_dim, 1, 1)\n",
        "        self.V = Parameter(torch.FloatTensor(hidden_dim), requires_grad=True)\n",
        "        self._inf = Parameter(torch.FloatTensor([float('-inf')]), requires_grad=False)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "        # Initialize vector V\n",
        "        nn.init.uniform(self.V, -1, 1)\n",
        "\n",
        "    def forward(self, input,\n",
        "                context,\n",
        "                mask):\n",
        "        \"\"\"\n",
        "        Attention - Forward-pass\n",
        "\n",
        "        :param Tensor input: Hidden state h\n",
        "        :param Tensor context: Attention context\n",
        "        :param ByteTensor mask: Selection mask\n",
        "        :return: tuple of - (Attentioned hidden state, Alphas)\n",
        "        \"\"\"\n",
        "\n",
        "        # (batch, hidden_dim, seq_len)\n",
        "        inp = self.input_linear(input).unsqueeze(2).expand(-1, -1, context.size(1))\n",
        "\n",
        "        # (batch, hidden_dim, seq_len)\n",
        "        context = context.permute(0, 2, 1)\n",
        "        ctx = self.context_linear(context)\n",
        "\n",
        "        # (batch, 1, hidden_dim)\n",
        "        V = self.V.unsqueeze(0).expand(context.size(0), -1).unsqueeze(1)\n",
        "\n",
        "        # (batch, seq_len)\n",
        "        att = torch.bmm(V, self.tanh(inp + ctx)).squeeze(1)\n",
        "        if len(att[mask]) > 0:\n",
        "            att[mask] = self.inf[mask]\n",
        "        alpha = self.softmax(att)\n",
        "\n",
        "        hidden_state = torch.bmm(ctx, alpha.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        return hidden_state, alpha\n",
        "\n",
        "    def init_inf(self, mask_size):\n",
        "        self.inf = self._inf.unsqueeze(1).expand(*mask_size)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder model for Pointer-Net\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim,\n",
        "                 hidden_dim):\n",
        "        \"\"\"\n",
        "        Initiate Decoder\n",
        "\n",
        "        :param int embedding_dim: Number of embeddings in Pointer-Net\n",
        "        :param int hidden_dim: Number of hidden units for the decoder's RNN\n",
        "        \"\"\"\n",
        "\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.input_to_hidden = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
        "        self.hidden_to_hidden = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
        "        self.hidden_out = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.att = Attention(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Used for propagating .cuda() command\n",
        "        self.mask = Parameter(torch.ones(1), requires_grad=False)\n",
        "        self.runner = Parameter(torch.zeros(1), requires_grad=False)\n",
        "\n",
        "    def forward(self, embedded_inputs,\n",
        "                decoder_input,\n",
        "                hidden,\n",
        "                context):\n",
        "        \"\"\"\n",
        "        Decoder - Forward-pass\n",
        "\n",
        "        :param Tensor embedded_inputs: Embedded inputs of Pointer-Net\n",
        "        :param Tensor decoder_input: First decoder's input\n",
        "        :param Tensor hidden: First decoder's hidden states\n",
        "        :param Tensor context: Encoder's outputs\n",
        "        :return: (Output probabilities, Pointers indices), last hidden state\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = embedded_inputs.size(0)\n",
        "        input_length = embedded_inputs.size(1)\n",
        "\n",
        "        # (batch, seq_len)\n",
        "        mask = self.mask.repeat(input_length).unsqueeze(0).repeat(batch_size, 1)\n",
        "        self.att.init_inf(mask.size())\n",
        "\n",
        "        # Generating arang(input_length), broadcasted across batch_size\n",
        "        runner = self.runner.repeat(input_length)\n",
        "        for i in range(input_length):\n",
        "            runner.data[i] = i\n",
        "        runner = runner.unsqueeze(0).expand(batch_size, -1).long()\n",
        "\n",
        "        outputs = []\n",
        "        pointers = []\n",
        "\n",
        "        def step(x, hidden):\n",
        "            \"\"\"\n",
        "            Recurrence step function\n",
        "\n",
        "            :param Tensor x: Input at time t\n",
        "            :param tuple(Tensor, Tensor) hidden: Hidden states at time t-1\n",
        "            :return: Hidden states at time t (h, c), Attention probabilities (Alpha)\n",
        "            \"\"\"\n",
        "\n",
        "            # Regular LSTM\n",
        "            h, c = hidden\n",
        "\n",
        "            gates = self.input_to_hidden(x) + self.hidden_to_hidden(h)\n",
        "            input, forget, cell, out = gates.chunk(4, 1)\n",
        "\n",
        "            input = torch.sigmoid(input)\n",
        "            forget = torch.sigmoid(forget)\n",
        "            cell = torch.tanh(cell)\n",
        "            out = torch.sigmoid(out)\n",
        "\n",
        "            c_t = (forget * c) + (input * cell)\n",
        "            h_t = out * torch.tanh(c_t)\n",
        "\n",
        "            # Attention section\n",
        "            hidden_t, output = self.att(h_t, context, torch.eq(mask, 0))\n",
        "            hidden_t = torch.tanh(self.hidden_out(torch.cat((hidden_t, h_t), 1)))\n",
        "\n",
        "            return hidden_t, c_t, output\n",
        "\n",
        "        # Recurrence loop\n",
        "        for _ in range(input_length):\n",
        "            h_t, c_t, outs = step(decoder_input, hidden)\n",
        "            hidden = (h_t, c_t)\n",
        "\n",
        "            # Masking selected inputs\n",
        "            masked_outs = outs * mask\n",
        "\n",
        "            # Get maximum probabilities and indices\n",
        "            max_probs, indices = masked_outs.max(1)\n",
        "            one_hot_pointers = (runner == indices.unsqueeze(1).expand(-1, outs.size()[1])).float()\n",
        "\n",
        "            # Update mask to ignore seen indices\n",
        "            mask  = mask * (1 - one_hot_pointers)\n",
        "\n",
        "            # Get embedded inputs by max indices\n",
        "            embedding_mask = one_hot_pointers.unsqueeze(2).expand(-1, -1, self.embedding_dim).byte()\n",
        "            decoder_input = embedded_inputs[embedding_mask.data].view(batch_size, self.embedding_dim)\n",
        "\n",
        "            outputs.append(outs.unsqueeze(0))\n",
        "            pointers.append(indices.unsqueeze(1))\n",
        "\n",
        "        outputs = torch.cat(outputs).permute(1, 0, 2)\n",
        "        pointers = torch.cat(pointers, 1)\n",
        "\n",
        "        return (outputs, pointers), hidden\n",
        "\n",
        "\n",
        "class PointerNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Pointer-Net\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 lstm_layers,\n",
        "                 dropout,\n",
        "                 bidir=False):\n",
        "        \"\"\"\n",
        "        Initiate Pointer-Net\n",
        "\n",
        "        :param int embedding_dim: Number of embbeding channels\n",
        "        :param int hidden_dim: Encoders hidden units\n",
        "        :param int lstm_layers: Number of layers for LSTMs\n",
        "        :param float dropout: Float between 0-1\n",
        "        :param bool bidir: Bidirectional\n",
        "        \"\"\"\n",
        "\n",
        "        super(PointerNet, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.bidir = bidir\n",
        "        self.embedding = nn.Linear(2, embedding_dim)\n",
        "        self.encoder = Encoder(embedding_dim,\n",
        "                               hidden_dim,\n",
        "                               lstm_layers,\n",
        "                               dropout,\n",
        "                               bidir)\n",
        "        self.decoder = Decoder(embedding_dim, hidden_dim)\n",
        "        self.decoder_input0 = Parameter(torch.FloatTensor(embedding_dim), requires_grad=False)\n",
        "\n",
        "        # Initialize decoder_input0\n",
        "        nn.init.uniform(self.decoder_input0, -1, 1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        PointerNet - Forward-pass\n",
        "\n",
        "        :param Tensor inputs: Input sequence\n",
        "        :return: Pointers probabilities and indices\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        input_length = inputs.size(1)\n",
        "\n",
        "        decoder_input0 = self.decoder_input0.unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        inputs = inputs.view(batch_size * input_length, -1)\n",
        "        embedded_inputs = self.embedding(inputs).view(batch_size, input_length, -1)\n",
        "\n",
        "        encoder_hidden0 = self.encoder.init_hidden(embedded_inputs)\n",
        "        encoder_outputs, encoder_hidden = self.encoder(embedded_inputs,\n",
        "                                                       encoder_hidden0)\n",
        "        if self.bidir:\n",
        "            decoder_hidden0 = (torch.cat(encoder_hidden[0][-2:], dim=-1),\n",
        "                               torch.cat(encoder_hidden[1][-2:], dim=-1))\n",
        "        else:\n",
        "            decoder_hidden0 = (encoder_hidden[0][-1],\n",
        "                               encoder_hidden[1][-1])\n",
        "        (outputs, pointers), decoder_hidden = self.decoder(embedded_inputs,\n",
        "                                                           decoder_input0,\n",
        "                                                           decoder_hidden0,\n",
        "                                                           encoder_outputs)\n",
        "\n",
        "        return  outputs, pointers"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii_1SepFLs2w"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"\n",
        " PyTorch DistilBERT model adapted in part from Facebook, Inc XLM model (https://github.com/facebookresearch/XLM) and in\n",
        " part from HuggingFace PyTorch version of Google AI Bert model (https://github.com/google-research/bert)\n",
        "\"\"\"\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "_CHECKPOINT_FOR_DOC = \"distilbert-base-uncased\"\n",
        "_CONFIG_FOR_DOC = \"DistilBertConfig\"\n",
        "_TOKENIZER_FOR_DOC = \"DistilBertTokenizer\"\n",
        "\n",
        "DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
        "    \"distilbert-base-uncased\",\n",
        "    \"distilbert-base-uncased-distilled-squad\",\n",
        "    \"distilbert-base-cased\",\n",
        "    \"distilbert-base-cased-distilled-squad\",\n",
        "    \"distilbert-base-german-cased\",\n",
        "    \"distilbert-base-multilingual-cased\",\n",
        "    \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    # See all DistilBERT models at https://huggingface.co/models?filter=distilbert\n",
        "]\n",
        "\n",
        "\n",
        "# UTILS AND BUILDING BLOCKS OF THE ARCHITECTURE #\n",
        "\n",
        "\n",
        "def create_sinusoidal_embeddings(n_pos, dim, out):\n",
        "    position_enc = np.array([[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)])\n",
        "    out.requires_grad = False\n",
        "    out[:, 0::2] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n",
        "    out[:, 1::2] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n",
        "    out.detach_()\n",
        "\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.dim, padding_idx=config.pad_token_id)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.dim)\n",
        "        if config.sinusoidal_pos_embds:\n",
        "\n",
        "            if is_deepspeed_zero3_enabled():\n",
        "                import deepspeed\n",
        "\n",
        "                with deepspeed.zero.GatheredParameters(self.position_embeddings.weight, modifier_rank=0):\n",
        "                    if torch.distributed.get_rank() == 0:\n",
        "                        create_sinusoidal_embeddings(\n",
        "                            n_pos=config.max_position_embeddings, dim=config.dim, out=self.position_embeddings.weight\n",
        "                        )\n",
        "            else:\n",
        "                create_sinusoidal_embeddings(\n",
        "                    n_pos=config.max_position_embeddings, dim=config.dim, out=self.position_embeddings.weight\n",
        "                )\n",
        "\n",
        "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            input_ids: torch.tensor(bs, max_seq_length) The token ids to embed.\n",
        "\n",
        "        Returns: torch.tensor(bs, max_seq_length, dim) The embedded tokens (plus position embeddings, no token_type\n",
        "        embeddings)\n",
        "        \"\"\"\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)  # (max_seq_length)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # (bs, max_seq_length)\n",
        "\n",
        "        word_embeddings = self.word_embeddings(input_ids)  # (bs, max_seq_length, dim)\n",
        "        position_embeddings = self.position_embeddings(position_ids)  # (bs, max_seq_length, dim)\n",
        "\n",
        "        embeddings = word_embeddings + position_embeddings  # (bs, max_seq_length, dim)\n",
        "        embeddings = self.LayerNorm(embeddings)  # (bs, max_seq_length, dim)\n",
        "        embeddings = self.dropout(embeddings)  # (bs, max_seq_length, dim)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_heads = config.n_heads\n",
        "        self.dim = config.dim\n",
        "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
        "\n",
        "        assert self.dim % self.n_heads == 0\n",
        "\n",
        "        self.q_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "        self.k_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "        self.v_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "        self.out_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
        "\n",
        "        self.pruned_heads = set()\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        attention_head_size = self.dim // self.n_heads\n",
        "        if len(heads) == 0:\n",
        "            return\n",
        "        heads, index = find_pruneable_heads_and_indices(heads, self.n_heads, attention_head_size, self.pruned_heads)\n",
        "        # Prune linear layers\n",
        "        self.q_lin = prune_linear_layer(self.q_lin, index)\n",
        "        self.k_lin = prune_linear_layer(self.k_lin, index)\n",
        "        self.v_lin = prune_linear_layer(self.v_lin, index)\n",
        "        self.out_lin = prune_linear_layer(self.out_lin, index, dim=1)\n",
        "        # Update hyper params\n",
        "        self.n_heads = self.n_heads - len(heads)\n",
        "        self.dim = attention_head_size * self.n_heads\n",
        "        self.pruned_heads = self.pruned_heads.union(heads)\n",
        "\n",
        "    def forward(self, query, key, value, mask, head_mask=None, output_attentions=False):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            query: torch.tensor(bs, seq_length, dim)\n",
        "            key: torch.tensor(bs, seq_length, dim)\n",
        "            value: torch.tensor(bs, seq_length, dim)\n",
        "            mask: torch.tensor(bs, seq_length)\n",
        "\n",
        "        Returns:\n",
        "            weights: torch.tensor(bs, n_heads, seq_length, seq_length) Attention weights context: torch.tensor(bs,\n",
        "            seq_length, dim) Contextualized layer. Optional: only if `output_attentions=True`\n",
        "        \"\"\"\n",
        "        bs, q_length, dim = query.size()\n",
        "        k_length = key.size(1)\n",
        "        # assert dim == self.dim, f'Dimensions do not match: {dim} input vs {self.dim} configured'\n",
        "        # assert key.size() == value.size()\n",
        "\n",
        "        dim_per_head = self.dim // self.n_heads\n",
        "\n",
        "        mask_reshp = (bs, 1, 1, k_length)\n",
        "\n",
        "        def shape(x):\n",
        "            \"\"\"separate heads\"\"\"\n",
        "            return x.view(bs, -1, self.n_heads, dim_per_head).transpose(1, 2)\n",
        "\n",
        "        def unshape(x):\n",
        "            \"\"\"group heads\"\"\"\n",
        "            return x.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * dim_per_head)\n",
        "\n",
        "        q = shape(self.q_lin(query))  # (bs, n_heads, q_length, dim_per_head)\n",
        "        k = shape(self.k_lin(key))  # (bs, n_heads, k_length, dim_per_head)\n",
        "        v = shape(self.v_lin(value))  # (bs, n_heads, k_length, dim_per_head)\n",
        "\n",
        "        q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
        "        scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\n",
        "        mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n",
        "        scores.masked_fill_(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)\n",
        "\n",
        "        weights = nn.Softmax(dim=-1)(scores)  # (bs, n_heads, q_length, k_length)\n",
        "        weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            weights = weights * head_mask\n",
        "\n",
        "        context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)\n",
        "        context = unshape(context)  # (bs, q_length, dim)\n",
        "        context = self.out_lin(context)  # (bs, q_length, dim)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context, weights)\n",
        "        else:\n",
        "            return (context,)\n",
        "\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        self.seq_len_dim = 1\n",
        "        self.lin1 = nn.Linear(in_features=config.dim, out_features=config.hidden_dim)\n",
        "        self.lin2 = nn.Linear(in_features=config.hidden_dim, out_features=config.dim)\n",
        "        assert config.activation in [\"relu\", \"gelu\"], f\"activation ({config.activation}) must be in ['relu', 'gelu']\"\n",
        "        self.activation = gelu if config.activation == \"gelu\" else nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)\n",
        "\n",
        "    def ff_chunk(self, input):\n",
        "        x = self.lin1(input)\n",
        "        x = self.activation(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        assert config.dim % config.n_heads == 0\n",
        "\n",
        "        self.attention = MultiHeadSelfAttention(config)\n",
        "        self.sa_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
        "\n",
        "        self.ffn = FFN(config)\n",
        "        self.output_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
        "\n",
        "    def forward(self, x, attn_mask=None, head_mask=None, output_attentions=False):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            x: torch.tensor(bs, seq_length, dim)\n",
        "            attn_mask: torch.tensor(bs, seq_length)\n",
        "\n",
        "        Returns:\n",
        "            sa_weights: torch.tensor(bs, n_heads, seq_length, seq_length) The attention weights ffn_output:\n",
        "            torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\n",
        "        \"\"\"\n",
        "        # Self-Attention\n",
        "        sa_output = self.attention(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            mask=attn_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        if output_attentions:\n",
        "            sa_output, sa_weights = sa_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
        "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
        "            assert type(sa_output) == tuple\n",
        "            sa_output = sa_output[0]\n",
        "        sa_output = self.sa_layer_norm(sa_output + x)  # (bs, seq_length, dim)\n",
        "\n",
        "        # Feed Forward Network\n",
        "        ffn_output = self.ffn(sa_output)  # (bs, seq_length, dim)\n",
        "        ffn_output = self.output_layer_norm(ffn_output + sa_output)  # (bs, seq_length, dim)\n",
        "\n",
        "        output = (ffn_output,)\n",
        "        if output_attentions:\n",
        "            output = (sa_weights,) + output\n",
        "        return output\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_layers = config.n_layers\n",
        "        self.layer = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
        "\n",
        "    def forward(\n",
        "        self, x, attn_mask=None, head_mask=None, output_attentions=False, output_hidden_states=False, return_dict=None\n",
        "    ):  # docstyle-ignore\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            x: torch.tensor(bs, seq_length, dim) Input sequence embedded.\n",
        "            attn_mask: torch.tensor(bs, seq_length) Attention mask on the sequence.\n",
        "\n",
        "        Returns:\n",
        "            hidden_state: torch.tensor(bs, seq_length, dim) Sequence of hidden states in the last (top)\n",
        "            layer all_hidden_states: Tuple[torch.tensor(bs, seq_length, dim)]\n",
        "                Tuple of length n_layers with the hidden states from each layer.\n",
        "                Optional: only if output_hidden_states=True\n",
        "            all_attentions: Tuple[torch.tensor(bs, n_heads, seq_length, seq_length)]\n",
        "                Tuple of length n_layers with the attention weights from each layer\n",
        "                Optional: only if output_attentions=True\n",
        "        \"\"\"\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        hidden_state = x\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_state,)\n",
        "\n",
        "            layer_outputs = layer_module(\n",
        "                x=hidden_state, attn_mask=attn_mask, head_mask=head_mask[i], output_attentions=output_attentions\n",
        "            )\n",
        "            hidden_state = layer_outputs[-1]\n",
        "\n",
        "            if output_attentions:\n",
        "                assert len(layer_outputs) == 2\n",
        "                attentions = layer_outputs[0]\n",
        "                all_attentions = all_attentions + (attentions,)\n",
        "            else:\n",
        "                assert len(layer_outputs) == 1\n",
        "\n",
        "        # Add last layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_state,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_state, all_hidden_states, all_attentions] if v is not None)\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=hidden_state, hidden_states=all_hidden_states, attentions=all_attentions\n",
        "        )\n",
        "\n",
        "\n",
        "# INTERFACE FOR ENCODER AND TASK SPECIFIC MODEL #\n",
        "class DistilBertPreTrainedModel(PreTrainedModel):\n",
        "    \"\"\"\n",
        "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
        "    models.\n",
        "    \"\"\"\n",
        "\n",
        "    config_class = DistilBertConfig\n",
        "    load_tf_weights = None\n",
        "    base_model_prefix = \"distilbert\"\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"Initialize the weights.\"\"\"\n",
        "        if isinstance(module, nn.Linear):\n",
        "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "\n",
        "DISTILBERT_START_DOCSTRING = r\"\"\"\n",
        "\n",
        "    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n",
        "    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n",
        "    pruning heads etc.)\n",
        "\n",
        "    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__\n",
        "    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to\n",
        "    general usage and behavior.\n",
        "\n",
        "    Parameters:\n",
        "        config (:class:`~transformers.DistilBertConfig`): Model configuration class with all the parameters of the model.\n",
        "            Initializing with a config file does not load the weights associated with the model, only the\n",
        "            configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model\n",
        "            weights.\n",
        "\"\"\"\n",
        "\n",
        "DISTILBERT_INPUTS_DOCSTRING = r\"\"\"\n",
        "    Args:\n",
        "        input_ids (:obj:`torch.LongTensor` of shape :obj:`({0})`):\n",
        "            Indices of input sequence tokens in the vocabulary.\n",
        "\n",
        "            Indices can be obtained using :class:`~transformers.DistilBertTokenizer`. See\n",
        "            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for\n",
        "            details.\n",
        "\n",
        "            `What are input IDs? <../glossary.html#input-ids>`__\n",
        "        attention_mask (:obj:`torch.FloatTensor` of shape :obj:`({0})`, `optional`):\n",
        "            Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n",
        "\n",
        "            - 1 for tokens that are **not masked**,\n",
        "            - 0 for tokens that are **masked**.\n",
        "\n",
        "            `What are attention masks? <../glossary.html#attention-mask>`__\n",
        "        head_mask (:obj:`torch.FloatTensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`):\n",
        "            Mask to nullify selected heads of the self-attention modules. Mask values selected in ``[0, 1]``:\n",
        "\n",
        "            - 1 indicates the head is **not masked**,\n",
        "            - 0 indicates the head is **masked**.\n",
        "\n",
        "        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`({0}, hidden_size)`, `optional`):\n",
        "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
        "            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated\n",
        "            vectors than the model's internal embedding lookup matrix.\n",
        "        output_attentions (:obj:`bool`, `optional`):\n",
        "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n",
        "            tensors for more detail.\n",
        "        output_hidden_states (:obj:`bool`, `optional`):\n",
        "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n",
        "            more detail.\n",
        "        return_dict (:obj:`bool`, `optional`):\n",
        "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class DistilBertModel(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        \n",
        "        self.hidden_size = config.hidden_dim\n",
        "        self.num_layers = 1\n",
        "        self.num_directions = 2 #because we are implementing it in bidirectional lstm mode\n",
        "\n",
        "        self.embeddings = Embeddings(config)  # Embeddings\n",
        "        self.transformer = Transformer(config)  # Encoder\n",
        "        self.pointer = PointerNet(64,128,1,0.0,False)\n",
        "       \n",
        "        self.init_weights()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embeddings.word_embeddings\n",
        "\n",
        "    def set_input_embeddings(self, new_embeddings):\n",
        "        self.embeddings.word_embeddings = new_embeddings\n",
        "\n",
        "    def _prune_heads(self, heads_to_prune):\n",
        "        \"\"\"\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n",
        "        class PreTrainedModel\n",
        "        \"\"\"\n",
        "        for layer, heads in heads_to_prune.items():\n",
        "            self.transformer.layer[layer].attention.prune_heads(heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)  # (bs, seq_length)\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embeddings(input_ids)  # (bs, seq_length, dim)\n",
        "        \n",
        "        \n",
        "        inputs_embed, ots=self.pointer(inputs_embeds.type(torch.float))\n",
        "        return self.transformer(\n",
        "            x=inputs_embeds,\n",
        "            attn_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "\n",
        "class DistilBertForQuestionAnsweringC(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.distilbert = DistilBertModel(config)\n",
        "        self.qa_outputs = nn.Linear(config.dim, config.num_labels)\n",
        "        assert config.num_labels == 2\n",
        "        self.dropout = nn.Dropout(config.qa_dropout)\n",
        "    \n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        start_positions=None,\n",
        "        end_positions=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n",
        "            sequence are not taken into account for computing the loss.\n",
        "        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n",
        "            sequence are not taken into account for computing the loss.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "     \n",
        "              \n",
        "        distilbert_output = self.distilbert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "\n",
        "        hidden_states = distilbert_output[0]  # (bs, max_query_len, dim)\n",
        "\n",
        "        hidden_states = self.dropout(hidden_states)  # (bs, max_query_len, dim)\n",
        "        logits = self.qa_outputs(hidden_states)  # (bs, max_query_len, 2)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1).contiguous()  # (bs, max_query_len)\n",
        "        end_logits = end_logits.squeeze(-1).contiguous()  # (bs, max_query_len)\n",
        "\n",
        "        total_loss = None\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            # If we are on multi-GPU, split add a dimension\n",
        "            if len(start_positions.size()) > 1:\n",
        "                start_positions = start_positions.squeeze(-1)\n",
        "            if len(end_positions.size()) > 1:\n",
        "                end_positions = end_positions.squeeze(-1)\n",
        "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
        "            ignored_index = start_logits.size(1)\n",
        "            start_positions = start_positions.clamp(0, ignored_index)\n",
        "            end_positions = end_positions.clamp(0, ignored_index)\n",
        "\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
        "            start_loss = loss_fct(start_logits, start_positions)\n",
        "            end_loss = loss_fct(end_logits, end_positions)\n",
        "            total_loss = (start_loss + end_loss) / 2\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (start_logits, end_logits) + distilbert_output[1:]\n",
        "            return ((total_loss,) + output) if total_loss is not None else output\n",
        "\n",
        "        return QuestionAnsweringModelOutput(\n",
        "            loss=total_loss,\n",
        "            start_logits=start_logits,\n",
        "            end_logits=end_logits,\n",
        "            hidden_states=distilbert_output.hidden_states,\n",
        "            attentions=distilbert_output.attentions,\n",
        "        )\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvI7-glYD-EO"
      },
      "source": [
        "## Initialize a tokenizer using DistilBERT which will help us tokenize our training questions and answers\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "## obtain encoded training and validation sets from the tokenizer\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDBQyklhh6XC"
      },
      "source": [
        "observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5smKlK_tEF_m"
      },
      "source": [
        "## Create a function to add token positions\n",
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "        # if None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQ912Ufh6XD"
      },
      "source": [
        "# 3. Train & Validation Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnnJ_bEmEH6K"
      },
      "source": [
        "## Creating the taining and validation datasets using the encoded training and validation sets we created in\n",
        "## the section above\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSWC1LFch6XD"
      },
      "source": [
        "### Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-47w4OPh6XE"
      },
      "source": [
        "# 4. Model Building & Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoCdp27JEMGd",
        "outputId": "1b3f4e1e-988b-4fc8-a026-0be496c49ea2"
      },
      "source": [
        "model =DistilBertForQuestionAnsweringC.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:105: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:290: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnsweringC: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnsweringC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnsweringC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnsweringC were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['distilbert.pointer.encoder.h0', 'distilbert.pointer.decoder.mask', 'distilbert.pointer.decoder.att.context_linear.bias', 'distilbert.pointer.decoder.att._inf', 'distilbert.pointer.decoder.input_to_hidden.weight', 'distilbert.pointer.decoder.hidden_out.bias', 'distilbert.pointer.decoder.att.input_linear.bias', 'distilbert.pointer.decoder.input_to_hidden.bias', 'distilbert.pointer.encoder.lstm.weight_hh_l0', 'distilbert.pointer.decoder.att.input_linear.weight', 'distilbert.pointer.decoder.att.V', 'distilbert.pointer.encoder.c0', 'distilbert.pointer.decoder_input0', 'distilbert.pointer.embedding.weight', 'distilbert.pointer.decoder.hidden_to_hidden.bias', 'distilbert.pointer.encoder.lstm.bias_hh_l0', 'distilbert.pointer.decoder.runner', 'distilbert.pointer.decoder.att.context_linear.weight', 'distilbert.pointer.embedding.bias', 'distilbert.pointer.encoder.lstm.bias_ih_l0', 'distilbert.pointer.decoder.hidden_to_hidden.weight', 'qa_outputs.weight', 'distilbert.pointer.decoder.hidden_out.weight', 'distilbert.pointer.encoder.lstm.weight_ih_l0', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k23zaN3Eh6XE"
      },
      "source": [
        "### Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3vssFehYeh4"
      },
      "source": [
        "# Training the created model using the available cuda gpu or cpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device) # send the model to the available device for training.\n",
        "model.train()\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=8,shuffle=False)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=3e-5)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viQzwiZvh6XE"
      },
      "source": [
        "### Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYhGxuR7Ls22"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ZDwxXNEe2T"
      },
      "source": [
        "### Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "d309cb3e578541de8a95791563efa0ff",
            "58f1a7c7172343649f4693de98d291aa",
            "837340b3b2b34e7085ab27dddaf53157",
            "d757344ed8cd45ae956a9f8af9960c8e",
            "df3bd1b491c742ff80153faa4c37752d",
            "50f0c78bda614eb28167241a6809d39c",
            "2290637fcd7d47f9ab78081d85d0b483",
            "5706923f2cb6441786ee67d138c42f59"
          ]
        },
        "id": "Hi8NlLE8EgTL",
        "scrolled": true,
        "outputId": "600430df-b49d-4a9b-9ca8-1de6a489069e"
      },
      "source": [
        "# Train for the model, perform validation on it per epoch and generate files for a tensorboard\n",
        "num_epochs = 10\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    tk0 = tqdm(train_dataloader, total=int(len(train_dataloader)))    \n",
        "    counter = 0\n",
        "    for idx,batch in enumerate(tk0):\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,start_positions=start_positions, end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        running_loss += loss.item() *  batch['input_ids'].size(0)\n",
        "        counter += 1\n",
        "        tk0.set_postfix(loss=(running_loss / (counter * train_dataloader.batch_size)))\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    writer.add_scalar('Train/Loss', epoch_loss,epoch)\n",
        "    print('Training Loss: {:.4f}'.format(epoch_loss))\n",
        "\n",
        "    model.eval()\n",
        "    running_val_loss=0\n",
        "    running_val_em=0\n",
        "    running_val_f1=0\n",
        "    tk1 = tqdm(val_dataloader, total=int(len(val_dataloader)))  \n",
        "    for idx,batch in enumerate(tk1):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        running_val_loss += loss.item() *  batch['input_ids'].size(0)\n",
        "        counter += 1\n",
        "        tk1.set_postfix(loss=(running_loss / (counter * val_dataloader.batch_size)))\n",
        "        answer_start = torch.argmax(outputs['start_logits'], dim=1)  \n",
        "        answer_end = torch.argmax(outputs['end_logits'], dim=1) + 1 \n",
        "        em_score, f1_score = calculate_stats(input_ids,answer_start,answer_end,idx)\n",
        "        running_val_em += em_score\n",
        "        running_val_f1 += f1_score\n",
        "    l = len(val_qac)\n",
        "    epoch_v_loss = running_val_loss /l\n",
        "    epoch_v_em = running_val_em/l\n",
        "    epoch_val_f1 = running_val_f1/l\n",
        "    writer.add_scalar('Val/Loss', epoch_v_loss,epoch)\n",
        "    writer.add_scalar('Val/EM', epoch_v_em,epoch)\n",
        "    writer.add_scalar('Val/F1', epoch_val_f1,epoch)\n",
        "    print('Val Loss: {:.4f}, EM: {:.4f}, F1: {:.4f} '.format(epoch_v_loss,epoch_v_em,epoch_val_f1))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d309cb3e578541de8a95791563efa0ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10853.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:246: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhaemVDrh6XG"
      },
      "source": [
        "### Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfNLO7vIGric"
      },
      "source": [
        "# We save our model so that it can be reused later\n",
        "\n",
        "torch.save(model,'./customBertmodelAdamW3e.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVFpfrIaG0Hc"
      },
      "source": [
        "# Generate a Tensorboard\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHB9zAzJh6XG"
      },
      "source": [
        "### Observations\n",
        "\n",
        "We have created a Tensorboard to map the loss and accuracy across the various epochs that the model has trained at.\n",
        "\n",
        "\n",
        "We will now run some examples to see how our model is performing & is it responding correctly to our questions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqECjsdPh6XG"
      },
      "source": [
        "# 5. Running The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daawyXdvh6XG"
      },
      "source": [
        "We will now test the model on some contexts and questions to see if we are getting the correct answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC-0FgOlHfrI"
      },
      "source": [
        "test_context = \"\"\"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\"\"\"\n",
        "\n",
        "\n",
        "test_question = \"\"\"Who was the Norse leader?\"\"\"\n",
        "\n",
        "test_answer =  \"Rollo\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5nclboJHkP6"
      },
      "source": [
        "def question_answer(question, context, model):\n",
        "    inputs = tokenizer(question,context, return_tensors='pt')\n",
        "\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    inputs.to(device)\n",
        "    start_scores, end_scores = model(input_ids, attention_mask=attention_mask, output_attentions=False)[:2]\n",
        "\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
        "    answer = tokenizer.convert_tokens_to_ids(answer.split())\n",
        "    answer = tokenizer.decode(answer)\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUPDhvCqh6XH"
      },
      "source": [
        "question_answer(test_question, test_context, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUL8iaTih6XH"
      },
      "source": [
        "question_answer(val_questions[0], val_contexts[0], model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cesK9qUgLs24"
      },
      "source": [
        "# Running The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsKW31A1h6XH"
      },
      "source": [
        "model_loaded = torch.load('./customBertmodel.pt')\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "test_context = \"\"\"The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\"\"\"\n",
        "test_question = \"\"\"Who was the Norse leader?\"\"\"\n",
        "test_answer =  \"Rollo\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQeTMe3uh6XH"
      },
      "source": [
        "def question_answer(question, context, model):\n",
        "    inputs = tokenizer(question,context, return_tensors='pt')\n",
        "\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    inputs.to(device)\n",
        "    start_scores, end_scores = model(input_ids, attention_mask=attention_mask, output_attentions=False)[:2]\n",
        "\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
        "    answer = tokenizer.convert_tokens_to_ids(answer.split())\n",
        "    answer = tokenizer.decode(answer)\n",
        "    return answer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZYdW6Th6XH"
      },
      "source": [
        "question_answer(test_question, test_context, model_loaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKjJpFgQh6XH"
      },
      "source": [
        "## we will now take some text at random from Wikipedia and test our model. This excerpt can be found at:\n",
        "## https://en.wikipedia.org/wiki/Long_short-term_memory under the Idea heading.\n",
        "context = \"\"\"In theory, classic (or \"vanilla\") RNNs can keep track of arbitrary long-term dependencies in the input sequences. The problem with vanilla RNNs is computational (or practical) in nature: when training a vanilla RNN using back-propagation, the gradients which are back-propagated can \"vanish\" (that is, they can tend to zero) or \"explode\" (that is, they can tend to infinity), because of the computations involved in the process, which use finite-precision numbers. RNNs using LSTM units partially solve the vanishing gradient problem, because LSTM units allow gradients to also flow unchanged. However, LSTM networks can still suffer from the exploding gradient problem.\"\"\"\n",
        "question = \"\"\"What problem can LSTM suffer from?\"\"\"\n",
        "answer = \"\"\"exploding gradient problem\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWVhCceh6XH"
      },
      "source": [
        "question_answer(question, context, model_loaded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPFYKaZrLs25"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(8)\n",
        "y = torch.split(x,2)\n",
        "y[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPXTi7JDLs26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}